{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7690850-3e0e-452b-bd63-e1af7c07196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from gymnasium import spaces\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e200cb3f-8fab-4c31-9264-dd34a892fd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleaveEnv(gym.Env):\n",
    "\n",
    "    metadata = {'render_modes': ['human']}\n",
    "\n",
    "    def __init__(self, csv_path, cnn_path, xgb_path):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cnn_surrogate = joblib.load(cnn_path)\n",
    "        self.xgb_surrogate = joblib.load(xgb_path)\n",
    "\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        len_fibers = len(self.df['FiberType'].unique())\n",
    "        \n",
    "        self.df = pd.get_dummies(self.df, columns=['FiberType'], dtype=np.int32)\n",
    "        \n",
    "        self.model_features = self.cnn_surrogate.feature_names_in_\n",
    "\n",
    "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
    "        self.max_tension_change = 10.0\n",
    "\n",
    "        \n",
    "        fiber_types = self.df.iloc[:, -len_fibers:]\n",
    "        other_inputs = self.df[['CleaveTension', 'Diameter']]\n",
    "        total_inputs = pd.concat([other_inputs, fiber_types], axis=1)\n",
    "        \n",
    "        self.context_df = total_inputs\n",
    "        observations_total = 1 + len(self.context_df.columns)\n",
    "\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(observations_total,), dtype=np.float32)\n",
    "\n",
    "        self.max_steps = 15\n",
    "        self.current_step = 0\n",
    "        self.current_context=None\n",
    "        self.current_tension = 0\n",
    "        self.render_mode = None\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        self.current_context = self.context_df.sample(n=1, random_state=self.np_random)\n",
    "\n",
    "        self.current_tension = self.current_context['CleaveTension'].iloc[0]\n",
    "        self.current_step = 0\n",
    "\n",
    "        last_cnn_pred = 0\n",
    "        last_xgb_pred = 0\n",
    "\n",
    "        observation = self._create_observation()#last_cnn_pred, last_xgb_pred)\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            print(\"\\n---------------EPISODE RESET----------------------\")\n",
    "            print(f\"New Scenario: Fiber = {self._get_current_fiber_type()} Start Tension = {self.current_tension:.0f}\")\n",
    "\n",
    "        return observation, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        delta_tension = float(action[0] * self.max_tension_change)\n",
    "        self.current_tension = self.current_tension + delta_tension\n",
    "        self.current_tension = np.clip(self.current_tension, 50, 2000)\n",
    "        self.current_step = self.current_step + 1\n",
    "\n",
    "        model_inputs = self.current_context.copy()\n",
    "        model_inputs['CleaveTension'] = self.current_tension\n",
    "        model_inputs = model_inputs[self.model_features]\n",
    "\n",
    "        #cnn_probs = self.cnn_surrogate.predict_proba(model_inputs)[0]\n",
    "        #xgb_probs = self.xgb_surrogate.predict_proba(model_inputs)[0]\n",
    "        \n",
    "        cnn_pred = self.cnn_surrogate.predict(model_inputs)[0]\n",
    "        xgb_pred = self.xgb_surrogate.predict(model_inputs)[0]\n",
    "\n",
    "        terminated = False\n",
    "        if cnn_pred == 1 and xgb_pred == 1:\n",
    "            reward = 100.0\n",
    "            terminated = True\n",
    "        elif cnn_pred == 1:\n",
    "            reward = 50.0\n",
    "        else:\n",
    "            reward = -3.0\n",
    "\n",
    "        if abs(delta_tension) < 1.0: \n",
    "            reward -= 2.0\n",
    "\n",
    "        SAFE_DELTA_THRESHOLD = 5.0\n",
    "\n",
    "        if abs(delta_tension) <= SAFE_DELTA_THRESHOLD:\n",
    "            reward += 1.5\n",
    "        else:\n",
    "            reward -= 0.25 * (abs(delta_tension) - SAFE_DELTA_THRESHOLD)\n",
    "\n",
    "        #action_cost = 0.1 * abs(delta_tension)\n",
    "        #reward = reward - action_cost\n",
    "\n",
    "        if(xgb_pred == 0 and delta_tension < 0) or \\\n",
    "        (xgb_pred == 2 and delta_tension > 0) or \\\n",
    "        (xgb_pred == 1 and abs(delta_tension) <=1.0):\n",
    "            reward += 1.0\n",
    "\n",
    "        truncated = self.current_step >= self.max_steps\n",
    "        if truncated and not terminated:\n",
    "            reward = reward - 25.0\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render(action, cnn_pred, xgb_pred, reward)\n",
    "        observation = self._create_observation()#cnn_pred, xgb_pred)\n",
    "        return observation, reward, terminated, truncated, {}\n",
    "\n",
    "    def _get_current_fiber_type(self):\n",
    "        for col_name in self.current_context.columns:\n",
    "            if 'FiberType_' in col_name and self.current_context[col_name].iloc[0] == 1.0:\n",
    "                return col_name.replace('FiberType_', '')\n",
    "        return \"Unknown\"\n",
    "\n",
    "    def _create_observation(self):#, #cnn_pred, xgb_pred):\n",
    "        return np.concatenate([\n",
    "            [self.current_tension],\n",
    "            #[cnn_pred, xgb_pred],\n",
    "            self.current_context.values[0]\n",
    "        ]).astype(np.float32)\n",
    "\n",
    "    def render(self, action, cnn_pred, xgb_pred, reward):\n",
    "        action_str = f\"{action[0]:+.2f}\"\n",
    "        cnn_str = \"GOOD\" if cnn_pred == 1 else \"BAD\"\n",
    "        xgb_map = {0: \"LOWER\", 1: \"SAME\", 2: \"RAISE\"}\n",
    "        xgb_str = xgb_map.get(xgb_pred, \"????\")\n",
    "\n",
    "        print(f\"Step {self.current_step:2d} Tension: {self.current_tension:6.1f} (Action: {action_str:6s}) -> CNN: {cnn_str:4s}, XGB: {xgb_str:5s} | Reward: {reward:6.1f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a4eccd20-7715-4d6c-bb67-d745c86e3740",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"C:\\\\Users\\\\clombardi\\\\RL\\\\data_updated.csv\"\n",
    "cnn_path= \"C:\\\\Users\\\\clombardi\\\\RL\\\\cnn_surrogate4.pkl\"\n",
    "xgb_path = \"C:\\\\Users\\\\clombardi\\\\RL\\\\xgb_surrogate4.pkl\"\n",
    "env = CleaveEnv(csv_path=csv_path, cnn_path=cnn_path, xgb_path=xgb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "64129ba2-052d-4ec9-8d0a-175892245c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import os\n",
    "\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "81b83ca5-20fd-419d-a149-776385679146",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = SAC(\n",
    "    \"MlpPolicy\",            \n",
    "    env,\n",
    "    device=\"cuda\",\n",
    "    verbose=0,\n",
    "    buffer_size=1000000,\n",
    "    ent_coef='auto',\n",
    "    learning_rate=1e-4,\n",
    "    batch_size=256,\n",
    "    tau=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "95017168-6928-4b6c-a855-dacde6285cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d39037024b0d44b686e3706474ca81aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.sac.sac.SAC at 0x25deab2fac0>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.learn(total_timesteps=5000, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "98133ef6-efef-47c3-988f-fba019a26fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_save_path = \"C:\\\\Users\\\\clombardi\\\\RL\\\\agent7\"\n",
    "agent.save(agent_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3e4e5fbc-d590-4c92-9ecb-0269ef4e2fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_agent = SAC.load(agent_save_path)\n",
    "eval_env = CleaveEnv(csv_path=csv_path, cnn_path=cnn_path, xgb_path=xgb_path)\n",
    "eval_env.render_mode = \"human\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9fdd5a31-a919-4a9b-b0af-1aa1563d830e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------EPISODE RESET----------------------\n",
      "New Scenario: Fiber = 400LA Start Tension = 1156\n",
      "Step  1 Tension: 1165.9 (Action: +0.99 ) -> CNN: BAD , XGB: SAME  | Reward:   -4.2\n",
      "Step  2 Tension: 1169.6 (Action: +0.36 ) -> CNN: BAD , XGB: SAME  | Reward:   -1.5\n",
      "Step  3 Tension: 1164.9 (Action: -0.47 ) -> CNN: BAD , XGB: SAME  | Reward:   -1.5\n",
      "Step  4 Tension: 1170.5 (Action: +0.56 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.2\n",
      "Step  5 Tension: 1164.2 (Action: -0.63 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.3\n",
      "Step  6 Tension: 1170.9 (Action: +0.66 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.4\n",
      "Step  7 Tension: 1164.1 (Action: -0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.4\n",
      "Step  8 Tension: 1170.9 (Action: +0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step  9 Tension: 1164.1 (Action: -0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step 10 Tension: 1170.9 (Action: +0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step 11 Tension: 1164.1 (Action: -0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step 12 Tension: 1170.9 (Action: +0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step 13 Tension: 1164.1 (Action: -0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step 14 Tension: 1170.9 (Action: +0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step 15 Tension: 1164.1 (Action: -0.68 ) -> CNN: BAD , XGB: SAME  | Reward:  -28.5\n",
      "Episode 1 finished with a total reward of: -73.25\n",
      "\n",
      "---------------EPISODE RESET----------------------\n",
      "New Scenario: Fiber = FG250LA Start Tension = 593\n",
      "Step  1 Tension:  603.0 (Action: +1.00 ) -> CNN: GOOD, XGB: SAME  | Reward:   98.8\n",
      "Episode 2 finished with a total reward of: 98.75\n",
      "\n",
      "---------------EPISODE RESET----------------------\n",
      "New Scenario: Fiber = 400LA Start Tension = 1150\n",
      "Step  1 Tension: 1160.0 (Action: +1.00 ) -> CNN: BAD , XGB: SAME  | Reward:   -4.2\n",
      "Step  2 Tension: 1165.1 (Action: +0.52 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.0\n",
      "Step  3 Tension: 1159.1 (Action: -0.60 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.3\n",
      "Step  4 Tension: 1165.6 (Action: +0.65 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.4\n",
      "Step  5 Tension: 1158.9 (Action: -0.67 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.4\n",
      "Step  6 Tension: 1165.7 (Action: +0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step  7 Tension: 1158.9 (Action: -0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step  8 Tension: 1165.7 (Action: +0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step  9 Tension: 1158.9 (Action: -0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step 10 Tension: 1165.7 (Action: +0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step 11 Tension: 1158.9 (Action: -0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step 12 Tension: 1165.7 (Action: +0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step 13 Tension: 1158.9 (Action: -0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step 14 Tension: 1165.7 (Action: +0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step 15 Tension: 1158.9 (Action: -0.68 ) -> CNN: BAD , XGB: SAME  | Reward:  -28.5\n",
      "Episode 3 finished with a total reward of: -76.93\n",
      "\n",
      "---------------EPISODE RESET----------------------\n",
      "New Scenario: Fiber = 400LA Start Tension = 1120\n",
      "Step  1 Tension: 1130.0 (Action: +1.00 ) -> CNN: BAD , XGB: SAME  | Reward:   -4.2\n",
      "Step  2 Tension: 1139.5 (Action: +0.95 ) -> CNN: BAD , XGB: SAME  | Reward:   -4.1\n",
      "Step  3 Tension: 1136.4 (Action: -0.31 ) -> CNN: BAD , XGB: SAME  | Reward:   -1.5\n",
      "Step  4 Tension: 1140.0 (Action: +0.36 ) -> CNN: BAD , XGB: SAME  | Reward:   -1.5\n",
      "Step  5 Tension: 1135.9 (Action: -0.42 ) -> CNN: BAD , XGB: SAME  | Reward:   -1.5\n",
      "Step  6 Tension: 1140.5 (Action: +0.46 ) -> CNN: BAD , XGB: SAME  | Reward:   -1.5\n",
      "Step  7 Tension: 1135.5 (Action: -0.50 ) -> CNN: BAD , XGB: SAME  | Reward:   -1.5\n",
      "Step  8 Tension: 1140.8 (Action: +0.53 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.1\n",
      "Step  9 Tension: 1135.3 (Action: -0.54 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.1\n",
      "Step 10 Tension: 1140.9 (Action: +0.55 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.1\n",
      "Step 11 Tension: 1135.3 (Action: -0.56 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.1\n",
      "Step 12 Tension: 1140.9 (Action: +0.56 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.2\n",
      "Step 13 Tension: 1135.3 (Action: -0.56 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.2\n",
      "Step 14 Tension: 1140.9 (Action: +0.56 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.2\n",
      "Step 15 Tension: 1135.3 (Action: -0.56 ) -> CNN: BAD , XGB: SAME  | Reward:  -28.2\n",
      "Episode 4 finished with a total reward of: -65.95\n",
      "\n",
      "---------------EPISODE RESET----------------------\n",
      "New Scenario: Fiber = 400LA Start Tension = 1198\n",
      "Step  1 Tension: 1206.4 (Action: +0.84 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.8\n",
      "Step  2 Tension: 1199.6 (Action: -0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step  3 Tension: 1206.4 (Action: +0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step  4 Tension: 1199.6 (Action: -0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step  5 Tension: 1206.4 (Action: +0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step  6 Tension: 1199.6 (Action: -0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step  7 Tension: 1206.4 (Action: +0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step  8 Tension: 1199.6 (Action: -0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step  9 Tension: 1206.4 (Action: +0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step 10 Tension: 1199.6 (Action: -0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step 11 Tension: 1206.4 (Action: +0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step 12 Tension: 1199.6 (Action: -0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step 13 Tension: 1206.4 (Action: +0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step 14 Tension: 1199.6 (Action: -0.68 ) -> CNN: BAD , XGB: SAME  | Reward:   -3.5\n",
      "Step 15 Tension: 1206.4 (Action: +0.68 ) -> CNN: BAD , XGB: SAME  | Reward:  -28.5\n",
      "Episode 5 finished with a total reward of: -77.29\n"
     ]
    }
   ],
   "source": [
    "for episode in range(5):\n",
    "        obs, info = eval_env.reset()\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        while not done:\n",
    "            action, _ = trained_agent.predict(obs, deterministic=True)\n",
    "            \n",
    "            obs, reward, terminated, truncated, info = eval_env.step(action)\n",
    "            \n",
    "            episode_reward += reward\n",
    "            done = terminated or truncated\n",
    "\n",
    "        print(f\"Episode {episode + 1} finished with a total reward of: {episode_reward:.2f}\")\n",
    "\n",
    "eval_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1acb447-2155-4323-b9cd-85348e16b211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
