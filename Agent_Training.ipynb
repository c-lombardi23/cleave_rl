{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7690850-3e0e-452b-bd63-e1af7c07196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "import joblib\n",
    "import os\n",
    "import pandas as pd\n",
    "from gymnasium import spaces\n",
    "from xgboost import XGBClassifier\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f03d844-e757-4172-908d-d06a15cfdcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "unified_model_path = \"G:\\\\Intern_Project_2025\\\\models\\\\Unified_classifier.keras\"\n",
    "unified_model = tf.keras.models.load_model(unified_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35c0e1d4-56b8-4a13-a69a-b3fe016b2a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"C:\\\\Users\\\\clombardi\\\\RL\\\\data.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "df['ImagePath'] = df['ImagePath'].apply(os.path.basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7424ff7-7c06-440a-b559-964742e448d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['CNN_Predicition'] == 1]\n",
    "ideal_tensions = dict(filtered_df.groupby('FiberType')['CleaveTension'].mean().astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bd0e199-4703-48c4-83e3-f00efa422c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "feature_output = unified_model.get_layer(\"global_avg\").output\n",
    "feature_extractor = Model(inputs=unified_model.input, outputs=feature_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c4774c5-b8ba-4971-9ca1-acf53405b893",
   "metadata": {},
   "outputs": [],
   "source": [
    " def mask_background(img: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"Mask background to prevent model from focusing on sharp gradient\n",
    "        near edges.\n",
    "\n",
    "        Args:\n",
    "            img: Image tensor of shape (H, W, C)\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: Image with circular mask applied\n",
    "        \"\"\"\n",
    "        h = tf.shape(img)[0]\n",
    "        w = tf.shape(img)[1]\n",
    "        y_range = tf.range(h)\n",
    "        x_range = tf.range(w)\n",
    "        yy, xx = tf.meshgrid(y_range, x_range, indexing=\"ij\")\n",
    "        center_x = tf.cast(w, tf.float32) / 2.0\n",
    "        center_y = tf.cast(h, tf.float32) / 2.0\n",
    "        radius = tf.minimum(center_x, center_y)\n",
    "        dist_from_center = tf.sqrt(\n",
    "            (tf.cast(xx, tf.float32) - center_x) ** 2\n",
    "            + (tf.cast(yy, tf.float32) - center_y) ** 2\n",
    "        )\n",
    "\n",
    "        mask = tf.cast(dist_from_center <= radius, tf.float32)\n",
    "        mask = tf.expand_dims(mask, axis=-1)\n",
    "        return img * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b35b8c01-0cd3-44bb-a126-bd7f4fa8e822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_process_images(filename: str, set_mask: bool) -> \"tf.Tensor\":\n",
    "    \"\"\"Load and preprocess image from file path.\n",
    "\n",
    "    Args:\n",
    "        filename: Image filename or path\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: Preprocessed image tensor\n",
    "    \"\"\"\n",
    "\n",
    "    if tf is None:\n",
    "        raise ImportError(\"TensorFlow is required for image processing\")\n",
    "\n",
    "    def load_image(file):\n",
    "        \"\"\"Load an image and process using same preprocessing as backbone.\n",
    "\n",
    "        Args:\n",
    "            file: path to image\n",
    "            preprocess_input: processing from backbone model\n",
    "\n",
    "        Returns:\n",
    "            loaded and resized image\n",
    "        \"\"\"\n",
    "        full_path = os.path.join(img_folder, file)\n",
    "\n",
    "        try:\n",
    "            img_raw = tf.io.read_file(full_path)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Image file not found: {full_path}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {full_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            img = tf.image.decode_png(img_raw, channels=1)\n",
    "            img = tf.image.resize(img, [224, 224])\n",
    "            img = tf.image.grayscale_to_rgb(img)\n",
    "            if set_mask == True:\n",
    "                img = mask_background(img)\n",
    "            return img\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {full_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "    img = load_image(filename)\n",
    "    img.set_shape([224, 224, 3])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "200e1e0b-5ce6-40cf-bf9b-10907290d167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "img_folder = \"C:\\\\Thorlabs\\\\combined_images\"\n",
    "features = []\n",
    "\n",
    "pred_features = df[\n",
    "                [\n",
    "                    \"CleaveAngle\",\n",
    "                    \"CleaveTension\",\n",
    "                    \"ScribeDiameter\",\n",
    "                    \"Misting\",\n",
    "                    \"Hackle\",\n",
    "                ]\n",
    "            ].values\n",
    "\n",
    "image_paths = df['ImagePath']\n",
    "\n",
    "for img_path, feature_vector in zip(image_paths, pred_features):\n",
    "    image = load_process_images(img_path, set_mask=False)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    feature_vector = np.expand_dims(feature_vector, axis=0)\n",
    "    feature_vector = np.zeros_like(feature_vector)\n",
    "    feat = feature_extractor.predict([image, feature_vector])[0]\n",
    "    features.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6663142a-4db8-4308-bf4e-d4dc3829b240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206, 1280)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.array(features)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e200cb3f-8fab-4c31-9264-dd34a892fd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleaveEnv(gym.Env):\n",
    "\n",
    "    metadata = {'render_modes': ['human']}\n",
    "\n",
    "    def __init__(self, csv_path, cnn_path, img_folder):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn_model = tf.keras.models.load_model(cnn_path)\n",
    "        self.img_folder = img_folder\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "\n",
    "        filtered_df = self.df[self.df['CNN_Predicition'] == 1]\n",
    "        self.ideal_tensions = dict(filtered_df.groupby('FiberType')['CleaveTension'].mean().astype(np.float32))\n",
    "        \n",
    "        len_fibers = len(self.df['FiberType'].unique())\n",
    "        \n",
    "        self.df = pd.get_dummies(self.df, columns=['FiberType'], dtype=np.int32)\n",
    "        \n",
    "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
    "        self.max_tension_change = 10.0\n",
    "\n",
    "        \n",
    "        fiber_types = self.df.iloc[:, -len_fibers:]\n",
    "        other_inputs = self.df['Diameter']\n",
    "        \n",
    "        combined_df = pd.concat([other_inputs, fiber_types], axis=1)\n",
    "        \n",
    "        self.context_df = combined_df\n",
    "        observations_total = 1 + len(self.context_df.columns)\n",
    "\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(observations_total,), dtype=np.float32)\n",
    "\n",
    "        self.max_steps = 15\n",
    "        self.current_step = 0\n",
    "        self.current_context=None\n",
    "        self.current_tension = 0\n",
    "        self.render_mode = None\n",
    "\n",
    "    def load_process_images(self, filename: str) -> \"tf.Tensor\":\n",
    "        \"\"\"Load and preprocess image from file path.\n",
    "    \n",
    "        Args:\n",
    "            filename: Image filename or path\n",
    "    \n",
    "        Returns:\n",
    "            tf.Tensor: Preprocessed image tensor\n",
    "        \"\"\"\n",
    "    \n",
    "        if tf is None:\n",
    "            raise ImportError(\"TensorFlow is required for image processing\")\n",
    "    \n",
    "        def load_image(file):\n",
    "            \"\"\"Load an image and process using same preprocessing as backbone.\n",
    "    \n",
    "            Args:\n",
    "                file: path to image\n",
    "                preprocess_input: processing from backbone model\n",
    "    \n",
    "            Returns:\n",
    "                loaded and resized image\n",
    "            \"\"\"\n",
    "            full_path = os.path.join(self.img_folder, file)\n",
    "    \n",
    "            try:\n",
    "                img_raw = tf.io.read_file(full_path)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Image file not found: {full_path}\")\n",
    "                return None\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {full_path}: {e}\")\n",
    "                return None\n",
    "    \n",
    "            try:\n",
    "                img = tf.image.decode_png(img_raw, channels=1)\n",
    "                img = tf.image.resize(img, [224, 224])\n",
    "                img = tf.image.grayscale_to_rgb(img)\n",
    "                return img\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {full_path}: {e}\")\n",
    "                return None\n",
    "    \n",
    "        img = load_image(filename)\n",
    "        img.set_shape([224, 224, 3])\n",
    "        return img\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        self.current_context = self.context_df.sample(n=1, random_state=self.np_random)\n",
    "        self.current_ideal_tension = self.ideal_tensions[self._get_current_fiber_type()]\n",
    "        self.current_tension = self.np_random.uniform(low=self.current_ideal_tension*(0.8), high=self.current_ideal_tension*(1.2))\n",
    "        self.current_step = 0\n",
    "\n",
    "        observation = self._create_observation()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            print(\"\\n---------------EPISODE RESET----------------------\")\n",
    "            print(f\"New Scenario: Fiber = {self._get_current_fiber_type()} Start Tension = {self.current_tension:.0f}\")\n",
    "\n",
    "        return observation, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        delta_tension = float(action[0] * self.max_tension_change)\n",
    "        self.current_tension = self.current_tension + delta_tension\n",
    "        self.current_tension = np.clip(self.current_tension, 50, 2000)\n",
    "        self.current_ideal_tension = self.ideal_tensions[self._get_current_fiber_type()]\n",
    "        \n",
    "        self.current_step = self.current_step + 1\n",
    "\n",
    "        model_inputs = self.current_context.copy()\n",
    "        model_inputs['CleaveTension'] = self.current_tension\n",
    "\n",
    "        row_index = self.current_context.index[0]\n",
    "        image_filename = self.df.iloc[row_index]['ImagePath']\n",
    "        image_tensor = self.load_process_images(image_filename)\n",
    "        \n",
    "        image_tensor = tf.expand_dims(image_tensor, axis=0)\n",
    "        \n",
    "        dummy_features = np.zeros((1, 5)) \n",
    "        cnn_raw = self.cnn_model.predict([image_tensor, dummy_features], verbose=0)\n",
    "        cnn_pred = cnn_raw[0][0]\n",
    "\n",
    "        terminated = False\n",
    "        if cnn_pred >= 0.63:\n",
    "            reward = 100.0\n",
    "            terminated = True\n",
    "        else:\n",
    "            reward = 50.0 * cnn_pred - 3.0 * (1 - cnn_pred)\n",
    "\n",
    "        SAFE_DELTA_THRESHOLD = 5.0\n",
    "\n",
    "        if abs(delta_tension) <= SAFE_DELTA_THRESHOLD:\n",
    "            reward += 1.5\n",
    "        else:\n",
    "            reward -= 0.25 * (abs(delta_tension) - SAFE_DELTA_THRESHOLD)\n",
    "\n",
    "        tension_error = abs(self.current_tension - self.current_ideal_tension)\n",
    "        reward += max(0, 1 - (tension_error / self.current_ideal_tension)) * 20.0\n",
    "\n",
    "        action_cost = 0.1 * abs(delta_tension)\n",
    "        reward = reward - action_cost\n",
    "\n",
    "        truncated = self.current_step >= self.max_steps\n",
    "        if truncated and not terminated:\n",
    "            reward = reward - 25.0\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render(action, cnn_pred, reward)\n",
    "        observation = self._create_observation()\n",
    "        return observation, float(reward), terminated, truncated, {}\n",
    "\n",
    "    def _get_current_fiber_type(self):\n",
    "        for col_name in self.current_context.columns:\n",
    "            if 'FiberType_' in col_name and self.current_context[col_name].iloc[0] == 1.0:\n",
    "                return col_name.replace('FiberType_', '')\n",
    "        return \"Unknown\"\n",
    "\n",
    "    def _create_observation(self):\n",
    "        return np.concatenate([\n",
    "            [self.current_tension],\n",
    "            self.current_context.values[0]\n",
    "        ]).astype(np.float32)\n",
    "\n",
    "    def render(self, action, cnn_pred, reward):\n",
    "        action_str = f\"{(action[0] *10.0):+.2f}\"\n",
    "        cnn_str = \"GOOD\" if cnn_pred > 0.63 else \"BAD\"\n",
    "        print(f\"Step {self.current_step:2d} Tension: {self.current_tension:6.1f} (Action: {action_str:6s}) -> CNN: {cnn_str:4s}| Reward: {reward:6.1f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a4eccd20-7715-4d6c-bb67-d745c86e3740",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"C:\\\\Users\\\\clombardi\\\\RL\\\\data.csv\"\n",
    "cnn_path= \"G:\\\\Intern_Project_2025\\\\models\\\\Unified_classifier.keras\"\n",
    "img_folder=\"C:\\\\Thorlabs\\\\combined_images\"\n",
    "env = CleaveEnv(csv_path=csv_path, cnn_path=cnn_path, img_folder=img_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "64129ba2-052d-4ec9-8d0a-175892245c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import os\n",
    "\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "81b83ca5-20fd-419d-a149-776385679146",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = SAC(\n",
    "    \"MlpPolicy\",            \n",
    "    env,\n",
    "    device=\"cuda\",\n",
    "    verbose=0,\n",
    "    buffer_size=1000000,\n",
    "    ent_coef='auto',\n",
    "    learning_rate=3e-4,\n",
    "    batch_size=1028,\n",
    "    tau=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c4dbc5bd-c915-4f55-af80-362c00b846ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3d262d491a4fe1a9757fcda4b2247e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.sac.sac.SAC at 0x2358c3e8430>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.learn(total_timesteps=5000, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "98133ef6-efef-47c3-988f-fba019a26fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_save_path = \"C:\\\\Users\\\\clombardi\\\\RL\\\\agent7\"\n",
    "#agent.save(agent_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3e4e5fbc-d590-4c92-9ecb-0269ef4e2fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_agent = SAC.load(agent_save_path)\n",
    "eval_env = CleaveEnv(csv_path=csv_path, cnn_path=cnn_path, img_folder=img_folder)\n",
    "eval_env.render_mode = \"human\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9fdd5a31-a919-4a9b-b0af-1aa1563d830e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------EPISODE RESET----------------------\n",
      "New Scenario: Fiber = 400LA Start Tension = 1308\n",
      "Step  1 Tension: 1300.6 (Action: -7.04 ) -> CNN: BAD | Reward:   17.8\n",
      "Step  2 Tension: 1293.9 (Action: -6.70 ) -> CNN: BAD | Reward:   18.1\n",
      "Step  3 Tension: 1287.6 (Action: -6.33 ) -> CNN: BAD | Reward:   18.3\n",
      "Step  4 Tension: 1281.7 (Action: -5.90 ) -> CNN: BAD | Reward:   18.6\n",
      "Step  5 Tension: 1276.3 (Action: -5.46 ) -> CNN: BAD | Reward:   18.9\n",
      "Step  6 Tension: 1271.2 (Action: -5.03 ) -> CNN: BAD | Reward:   19.2\n",
      "Step  7 Tension: 1266.6 (Action: -4.61 ) -> CNN: BAD | Reward:   20.8\n",
      "Step  8 Tension: 1262.4 (Action: -4.21 ) -> CNN: BAD | Reward:   20.9\n",
      "Step  9 Tension: 1258.6 (Action: -3.83 ) -> CNN: BAD | Reward:   21.1\n",
      "Step 10 Tension: 1255.1 (Action: -3.46 ) -> CNN: BAD | Reward:   21.2\n",
      "Step 11 Tension: 1252.2 (Action: -2.93 ) -> CNN: BAD | Reward:   21.3\n",
      "Step 12 Tension: 1249.7 (Action: -2.45 ) -> CNN: BAD | Reward:   21.4\n",
      "Step 13 Tension: 1247.7 (Action: -2.03 ) -> CNN: BAD | Reward:   21.5\n",
      "Step 14 Tension: 1246.0 (Action: -1.68 ) -> CNN: BAD | Reward:   21.6\n",
      "Step 15 Tension: 1244.6 (Action: -1.39 ) -> CNN: BAD | Reward:   -3.4\n",
      "Episode 1 finished with a total reward of: 277.24\n",
      "\n",
      "---------------EPISODE RESET----------------------\n",
      "New Scenario: Fiber = 400LA Start Tension = 1108\n",
      "Step  1 Tension: 1116.3 (Action: +8.78 ) -> CNN: BAD | Reward:   20.1\n",
      "Step  2 Tension: 1125.1 (Action: +8.79 ) -> CNN: BAD | Reward:   20.2\n",
      "Step  3 Tension: 1133.9 (Action: +8.80 ) -> CNN: BAD | Reward:   20.0\n",
      "Step  4 Tension: 1142.7 (Action: +8.81 ) -> CNN: BAD | Reward:   19.8\n",
      "Step  5 Tension: 1151.5 (Action: +8.79 ) -> CNN: BAD | Reward:   19.6\n",
      "Step  6 Tension: 1160.2 (Action: +8.70 ) -> CNN: BAD | Reward:   19.4\n",
      "Step  7 Tension: 1168.8 (Action: +8.57 ) -> CNN: BAD | Reward:   19.3\n",
      "Step  8 Tension: 1177.1 (Action: +8.33 ) -> CNN: BAD | Reward:   19.2\n",
      "Step  9 Tension: 1185.0 (Action: +7.88 ) -> CNN: BAD | Reward:   19.1\n",
      "Step 10 Tension: 1192.3 (Action: +7.29 ) -> CNN: BAD | Reward:   19.2\n",
      "Step 11 Tension: 1198.9 (Action: +6.63 ) -> CNN: BAD | Reward:   19.3\n",
      "Step 12 Tension: 1204.9 (Action: +5.92 ) -> CNN: BAD | Reward:   19.4\n",
      "Step 13 Tension: 1210.1 (Action: +5.20 ) -> CNN: BAD | Reward:   19.5\n",
      "Step 14 Tension: 1214.6 (Action: +4.50 ) -> CNN: BAD | Reward:   21.0\n",
      "Step 15 Tension: 1218.4 (Action: +3.84 ) -> CNN: BAD | Reward:   -4.0\n",
      "Episode 2 finished with a total reward of: 270.91\n",
      "\n",
      "---------------EPISODE RESET----------------------\n",
      "New Scenario: Fiber = 400LA Start Tension = 1091\n",
      "Step  1 Tension: 1099.7 (Action: +8.76 ) -> CNN: BAD | Reward:   35.4\n",
      "Step  2 Tension: 1108.5 (Action: +8.77 ) -> CNN: BAD | Reward:   35.6\n",
      "Step  3 Tension: 1117.2 (Action: +8.78 ) -> CNN: BAD | Reward:   35.7\n",
      "Step  4 Tension: 1126.0 (Action: +8.79 ) -> CNN: BAD | Reward:   35.8\n",
      "Step  5 Tension: 1134.8 (Action: +8.80 ) -> CNN: BAD | Reward:   35.6\n",
      "Step  6 Tension: 1143.7 (Action: +8.81 ) -> CNN: BAD | Reward:   35.4\n",
      "Step  7 Tension: 1152.4 (Action: +8.78 ) -> CNN: BAD | Reward:   35.2\n",
      "Step  8 Tension: 1161.1 (Action: +8.69 ) -> CNN: BAD | Reward:   35.1\n",
      "Step  9 Tension: 1169.7 (Action: +8.56 ) -> CNN: BAD | Reward:   34.9\n",
      "Step 10 Tension: 1178.0 (Action: +8.31 ) -> CNN: BAD | Reward:   34.8\n",
      "Step 11 Tension: 1185.8 (Action: +7.85 ) -> CNN: BAD | Reward:   34.8\n",
      "Step 12 Tension: 1193.1 (Action: +7.25 ) -> CNN: BAD | Reward:   34.9\n",
      "Step 13 Tension: 1199.7 (Action: +6.59 ) -> CNN: BAD | Reward:   34.9\n",
      "Step 14 Tension: 1205.6 (Action: +5.88 ) -> CNN: BAD | Reward:   35.1\n",
      "Step 15 Tension: 1210.7 (Action: +5.15 ) -> CNN: BAD | Reward:   10.2\n",
      "Episode 3 finished with a total reward of: 503.38\n",
      "\n",
      "---------------EPISODE RESET----------------------\n",
      "New Scenario: Fiber = 400LA Start Tension = 1085\n",
      "Step  1 Tension: 1093.9 (Action: +8.75 ) -> CNN: BAD | Reward:   19.6\n",
      "Step  2 Tension: 1102.6 (Action: +8.76 ) -> CNN: BAD | Reward:   19.7\n",
      "Step  3 Tension: 1111.4 (Action: +8.77 ) -> CNN: BAD | Reward:   19.9\n",
      "Step  4 Tension: 1120.2 (Action: +8.79 ) -> CNN: BAD | Reward:   20.1\n",
      "Step  5 Tension: 1129.0 (Action: +8.80 ) -> CNN: BAD | Reward:   20.1\n",
      "Step  6 Tension: 1137.8 (Action: +8.81 ) -> CNN: BAD | Reward:   19.9\n",
      "Step  7 Tension: 1146.6 (Action: +8.82 ) -> CNN: BAD | Reward:   19.7\n",
      "Step  8 Tension: 1155.4 (Action: +8.78 ) -> CNN: BAD | Reward:   19.5\n",
      "Step  9 Tension: 1164.1 (Action: +8.68 ) -> CNN: BAD | Reward:   19.3\n",
      "Step 10 Tension: 1172.6 (Action: +8.55 ) -> CNN: BAD | Reward:   19.2\n",
      "Step 11 Tension: 1180.9 (Action: +8.26 ) -> CNN: BAD | Reward:   19.1\n",
      "Step 12 Tension: 1188.7 (Action: +7.77 ) -> CNN: BAD | Reward:   19.1\n",
      "Step 13 Tension: 1195.8 (Action: +7.17 ) -> CNN: BAD | Reward:   19.1\n",
      "Step 14 Tension: 1202.3 (Action: +6.50 ) -> CNN: BAD | Reward:   19.2\n",
      "Step 15 Tension: 1208.1 (Action: +5.78 ) -> CNN: BAD | Reward:   -5.6\n",
      "Episode 4 finished with a total reward of: 267.88\n",
      "\n",
      "---------------EPISODE RESET----------------------\n",
      "New Scenario: Fiber = 400LA Start Tension = 972\n",
      "Step  1 Tension:  980.3 (Action: +8.58 ) -> CNN: BAD | Reward:   18.3\n",
      "Step  2 Tension:  988.9 (Action: +8.60 ) -> CNN: BAD | Reward:   18.5\n",
      "Step  3 Tension:  997.5 (Action: +8.61 ) -> CNN: BAD | Reward:   18.7\n",
      "Step  4 Tension: 1006.1 (Action: +8.62 ) -> CNN: BAD | Reward:   18.9\n",
      "Step  5 Tension: 1014.8 (Action: +8.64 ) -> CNN: BAD | Reward:   19.1\n",
      "Step  6 Tension: 1023.4 (Action: +8.65 ) -> CNN: BAD | Reward:   19.3\n",
      "Step  7 Tension: 1032.1 (Action: +8.66 ) -> CNN: BAD | Reward:   19.5\n",
      "Step  8 Tension: 1040.8 (Action: +8.67 ) -> CNN: BAD | Reward:   19.6\n",
      "Step  9 Tension: 1049.5 (Action: +8.69 ) -> CNN: BAD | Reward:   19.8\n",
      "Step 10 Tension: 1058.2 (Action: +8.70 ) -> CNN: BAD | Reward:   20.0\n",
      "Step 11 Tension: 1066.9 (Action: +8.71 ) -> CNN: BAD | Reward:   20.2\n",
      "Step 12 Tension: 1075.6 (Action: +8.72 ) -> CNN: BAD | Reward:   20.4\n",
      "Step 13 Tension: 1084.3 (Action: +8.74 ) -> CNN: BAD | Reward:   20.6\n",
      "Step 14 Tension: 1093.1 (Action: +8.75 ) -> CNN: BAD | Reward:   20.8\n",
      "Step 15 Tension: 1101.8 (Action: +8.76 ) -> CNN: BAD | Reward:   -4.0\n",
      "Episode 5 finished with a total reward of: 269.71\n"
     ]
    }
   ],
   "source": [
    "for episode in range(5):\n",
    "        obs, info = eval_env.reset()\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        while not done:\n",
    "            action, _ = trained_agent.predict(obs, deterministic=True)\n",
    "            \n",
    "            obs, reward, terminated, truncated, info = eval_env.step(action)\n",
    "            \n",
    "            episode_reward += reward\n",
    "            done = terminated or truncated\n",
    "\n",
    "        print(f\"Episode {episode + 1} finished with a total reward of: {episode_reward:.2f}\")\n",
    "\n",
    "eval_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da518bd7-35ba-4cec-b4af-d5b67092b28e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
